{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as req\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape using BeautifulSoup\n",
    "### Scrape Nasa for top news story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://mars.nasa.gov/news/\"\n",
    "response = req.get(url)\n",
    "\n",
    "soup = bs(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting title and text from most recent news article\n",
    "soup_split = soup.find(class_='slide') \n",
    "soup_split1 = soup_split.find_all('a')\n",
    "news_title = soup_split1[1].get_text().strip()\n",
    "news_p = soup_split1[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape using Splinter\n",
    "### Scrape JPL for top image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url_2 = \"https://www.jpl.nasa.gov\"\n",
    "url_2 = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "img = soup.find('a', class_='button fancybox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "browser.click_link_by_partial_text('more info')\n",
    "new_url = browser.url\n",
    "browser.visit(new_url)\n",
    "html2 = browser.html\n",
    "soup2 = bs(html2, 'html.parser')\n",
    "img = soup2.find('figure')\n",
    "img = img.find('a')['href']\n",
    "featured_image_url = base_url_2 + img\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape using BeautifulSoup\n",
    "### Scrape Nasa's twitter for mose recent tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = \"https://twitter.com/marswxreport?lang=en\"\n",
    "response3 = req.get(url3)\n",
    "\n",
    "soup3 = bs(response3.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = soup3.find(class_='js-tweet-text-container')\n",
    "mars_weather = tweet.find('p').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape using Pandas\n",
    "### Scrape space-facts website for Mars data table and convert table to html string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = \"https://space-facts.com/mars/\"\n",
    "tables = pd.read_html(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = tables[0].to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape using BeautifulSoup\n",
    "### Scrape astrogeology.usgs.gov website for pictures and description of each hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url4 = \"https://astrogeology.usgs.gov\"\n",
    "url4 = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "response4 = req.get(url4)\n",
    "\n",
    "soup4 = bs(response4.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_items = soup4.find_all(class_=\"item\")\n",
    "img_url = []\n",
    "title = []\n",
    "for image in list_items:\n",
    "    image = image.find('a')['href']\n",
    "\n",
    "    respons = req.get(base_url4+image)\n",
    "\n",
    "    soup5 = bs(respons.text, 'html.parser')\n",
    "    title_text = soup5.find(class_=\"title\").get_text()\n",
    "    title.append(title_text)\n",
    "    pic = soup5.find('li')\n",
    "    pic = pic.find('a')['href']\n",
    "    img_url.append(pic)\n",
    "#     case = {'title': title, 'img_url': img_url}\n",
    "#     hemisphere_image_urls.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = {} \n",
    "for key in title: \n",
    "    for value in img_url: \n",
    "        hemisphere_image_urls[key] = value \n",
    "        img_url.remove(value) \n",
    "        break  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
